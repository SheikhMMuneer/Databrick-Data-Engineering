{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"91dbfbb7-e5c5-425d-b6a5-f153b231cae6","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"51f698bd-880b-4a85-b187-9b96d8c2cf18\"/>\n\n\n# Lab: Orchestrating Jobs with Databricks\n\nIn this lab, you'll be configuring a multi-task job comprising of:\n* A notebook that lands a new batch of data in a storage directory\n* A Delta Live Table pipeline that processes this data through a series of tables\n* A notebook that queries the gold table produced by this pipeline as well as various metrics output by DLT\n\n## Learning Objectives\nBy the end of this lab, you should be able to:\n* Schedule a notebook as a task in a Databricks Job\n* Schedule a DLT pipeline as a task in a Databricks Job\n* Configure linear dependencies between tasks using the Databricks Workflows UI"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"85a62bfd-69a9-4c51-b088-d299625c5261","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%run ../../Includes/Classroom-Setup-09.2.1L"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6f2f3c84-9bd2-4ae3-8818-0e8869761260","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Python interpreter will be restarted.\nPython interpreter will be restarted.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Python interpreter will be restarted.\nPython interpreter will be restarted.\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02\"\n\nValidating the locally installed datasets:\n| listing local files...(7 seconds)\n| completed (7 seconds total)\n\nCreating & using the schema \"munirsheikhcloudseekho_0lj9_da_dewd_jobs_lab_92\"...(1 seconds)\nPredefined tables in \"munirsheikhcloudseekho_0lj9_da_dewd_jobs_lab_92\":\n| -none-\n\nPredefined paths variables:\n| DA.paths.working_dir:      dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92\n| DA.paths.user_db:          dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/database.db\n| DA.paths.datasets:         dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02\n| DA.paths.checkpoints:      dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/_checkpoints\n| DA.paths.stream_path:      dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/stream\n| DA.paths.storage_location: dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/storage\n\nSetup completed (10 seconds)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02\"\n\nValidating the locally installed datasets:\n| listing local files...(7 seconds)\n| completed (7 seconds total)\n\nCreating & using the schema \"munirsheikhcloudseekho_0lj9_da_dewd_jobs_lab_92\"...(1 seconds)\nPredefined tables in \"munirsheikhcloudseekho_0lj9_da_dewd_jobs_lab_92\":\n| -none-\n\nPredefined paths variables:\n| DA.paths.working_dir:      dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92\n| DA.paths.user_db:          dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/database.db\n| DA.paths.datasets:         dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02\n| DA.paths.checkpoints:      dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/_checkpoints\n| DA.paths.stream_path:      dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/stream\n| DA.paths.storage_location: dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/storage\n\nSetup completed (10 seconds)\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"b7163714-376c-41fd-8e38-80a7247fa923\"/>\n\n\n## Land Initial Data\nSeed the landing zone with some data before proceeding. You will re-run this command to land additional data later."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aca6913d-0273-4c8a-8dc4-9b7f4f5ef419","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["DA.data_factory.load()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"84e5bd4a-29f8-4887-ac45-b9a96e82fbfa","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Loading the file 01.json to the dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/stream/01.json\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Loading the file 01.json to the dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/stream/01.json\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"6bc33560-37f4-4f91-910d-669a1708ba66\"/>\n\n\n## Create and Configure a Pipeline\n\nThe pipeline we create here is nearly identical to the one in the previous unit.\n\nWe will use it as part of a scheduled job in this lesson.\n\nExecute the following cell to print out the values that will be used during the following configuration steps."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3b3d0358-048e-44cd-80ec-1e591715d151","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["DA.print_pipeline_config()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"05c884d3-242a-4514-986a-50a8f569e5c9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<table style=\"width:100%\">\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Pipeline Name:</td>\n        <td><input type=\"text\" value=\"DLT-Job-Lab-92-munirsheikhcloudseekho@gmail.com\" style=\"width:100%\"></td></tr>\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Target:</td>\n        <td><input type=\"text\" value=\"munirsheikhcloudseekho_0lj9_da_dewd_jobs_lab_92\" style=\"width:100%\"></td></tr>\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Storage Location:</td>\n        <td><input type=\"text\" value=\"dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/storage\" style=\"width:100%\"></td></tr>\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Notebook Path:</td>\n        <td><input type=\"text\" value=\"/Users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/data-engineering-with-databricks/Solutions/09 - Task Orchestration with Jobs/DE 9.2L - Jobs Lab/DE 9.2.3L - DLT Job\" style=\"width:100%\"></td></tr>\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Datasets Path:</td>\n        <td><input type=\"text\" value=\"dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02\" style=\"width:100%\"></td></tr>\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Source:</td>\n        <td><input type=\"text\" value=\"dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/stream\" style=\"width:100%\"></td></tr>\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Policy:</td>\n        <td><input type=\"text\" value=\"DBAcademy DLT-Only Policy\" style=\"width:100%\"></td></tr>\n    </table>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<table style=\"width:100%\">\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Pipeline Name:</td>\n        <td><input type=\"text\" value=\"DLT-Job-Lab-92-munirsheikhcloudseekho@gmail.com\" style=\"width:100%\"></td></tr>\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Target:</td>\n        <td><input type=\"text\" value=\"munirsheikhcloudseekho_0lj9_da_dewd_jobs_lab_92\" style=\"width:100%\"></td></tr>\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Storage Location:</td>\n        <td><input type=\"text\" value=\"dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/storage\" style=\"width:100%\"></td></tr>\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Notebook Path:</td>\n        <td><input type=\"text\" value=\"/Users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/data-engineering-with-databricks/Solutions/09 - Task Orchestration with Jobs/DE 9.2L - Jobs Lab/DE 9.2.3L - DLT Job\" style=\"width:100%\"></td></tr>\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Datasets Path:</td>\n        <td><input type=\"text\" value=\"dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02\" style=\"width:100%\"></td></tr>\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Source:</td>\n        <td><input type=\"text\" value=\"dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/jobs_lab_92/stream\" style=\"width:100%\"></td></tr>\n    <tr>\n        <td style=\"white-space:nowrap; width:1em\">Policy:</td>\n        <td><input type=\"text\" value=\"DBAcademy DLT-Only Policy\" style=\"width:100%\"></td></tr>\n    </table>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"c8b235db-10cf-4a56-92d9-330b80da4f0f\"/>\n\n\nSteps:\n1. Click the **Workflows** button on the sidebar.\n1. Select the **Delta Live Tables** tab.\n1. Click **Create Pipeline**.\n1. Leave **Product Edition** as **Advanced**.\n1. Fill in a **Pipeline Name** - because these names must be unique, we suggest using the **Pipeline Name** provided in the cell above.\n1. For **Notebook Libraries**, use the navigator to locate and select the notebook specified above.\n1. Under **Configuration**, add three configuration parameters:\n   * Click **Add configuration**, set the \"key\" to **spark.master** and the \"value\" to **local[\\*]**.\n   * Click **Add configuration**, set the \"key\" to **datasets_path** and the \"value\" to the value provided in the cell above.\n   * Click **Add configuration**, set the \"key\" to **source** and the \"value\" to the value provided in the cell above.\n1. In the **Target** field, enter the database name provided in the cell above.<br/>\nThis should follow the pattern **`<name>_<hash>_dbacademy_dewd_jobs_lab_92`**\n1. In the **Storage location** field, enter the path provided in the cell above.\n1. For **Pipeline Mode**, select **Triggered**.\n1. Uncheck the **Enable autoscaling** box.\n1. Set the number of **`workers`** to **`0`** (zero).\n1. Check the **Use Photon Acceleration** box.\n1. For **Channel**, select **Current**\n1. For **Policy**, select the value provided in the cell above.\n\nFinally, click **Create**.\n\n<img src=\"https://files.training.databricks.com/images/icon_note_24.png\"> **Note**: we won't be executing this pipline directly as it will be executed by our job later in this lesson,<br/>\nbut if you want to test it real quick, you can click the **Start** button now."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3ec5050d-cbc4-490d-be0f-c6ccaa0ac5ea","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# ANSWER\n \n# This function is provided for students who do not \n# want to work through the exercise of creating the pipeline.\nDA.create_pipeline()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f9593bbd-375a-4710-80e1-9d016567c92d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-4094000743659299>\u001B[0m in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# This function is provided for students who do not\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# want to work through the exercise of creating the pipeline.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mDA\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m<command-4094000743658882>\u001B[0m in \u001B[0;36mcreate_pipeline\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;31m# We need to delete the existing pipline so that we can apply updates\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0;31m# because some attributes are not mutable after creation.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpipelines\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdelete_by_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpipeline_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     response = self.client.pipelines().create(\n\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-f337616f-e42d-48be-b0bd-7d44fa0293ed/lib/python3.9/site-packages/dbacademy/dbrest/pipelines.py\u001B[0m in \u001B[0;36mdelete_by_name\u001B[0;34m(self, pipeline_name)\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdelete_by_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpipeline_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m         \u001B[0;32mimport\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m         \u001B[0mpipeline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_by_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpipeline_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mpipeline\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdelete_by_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"pipeline_id\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-f337616f-e42d-48be-b0bd-7d44fa0293ed/lib/python3.9/site-packages/dbacademy/dbrest/pipelines.py\u001B[0m in \u001B[0;36mget_by_name\u001B[0;34m(self, pipeline_name)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_by_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpipeline_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 36\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mpipeline\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     37\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"name\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mpipeline_name\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m                 \u001B[0mpipeline_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"pipeline_id\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-f337616f-e42d-48be-b0bd-7d44fa0293ed/lib/python3.9/site-packages/dbacademy/dbrest/pipelines.py\u001B[0m in \u001B[0;36mlist\u001B[0;34m(self, max_results)\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_results\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0mpipelines\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapi\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"GET\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf\"{self.base_uri}?max_results={max_results}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-f337616f-e42d-48be-b0bd-7d44fa0293ed/lib/python3.9/site-packages/dbacademy/rest/common.py\u001B[0m in \u001B[0;36mapi\u001B[0;34m(self, _http_method, _endpoint_path, _data, _expected, _result_type, _base_url, **data)\u001B[0m\n\u001B[1;32m    189\u001B[0m             \u001B[0;31m# if self.verbose: print(json.dumps(data, indent=4))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_http_method\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdumps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 191\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_raise_for_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_expected\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    192\u001B[0m         \u001B[0;31m# TODO: Should we really return None on errors?  Kept for now for backwards compatibility.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    193\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m200\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatus_code\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m300\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-f337616f-e42d-48be-b0bd-7d44fa0293ed/lib/python3.9/site-packages/dbacademy/rest/common.py\u001B[0m in \u001B[0;36m_raise_for_status\u001B[0;34m(response, expected)\u001B[0m\n\u001B[1;32m    282\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;36m400\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatus_code\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m500\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    283\u001B[0m             \u001B[0me\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDatabricksApiException\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhttp_exception\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 284\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    285\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    286\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mdeprecated\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreason\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"Use ApiClient.api\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maction\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"error\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mHTTPError\u001B[0m: 503 Server Error: Service Unavailable for url: https://community.cloud.databricks.com/api/2.0/pipelines?max_results=100\n Response from server: \n { 'error_code': 'TEMPORARILY_UNAVAILABLE',\n  'message': 'The service at /api/2.0/pipelines is temporarily unavailable. '\n             'Please try again later.'}","errorSummary":"<span class='ansi-red-fg'>HTTPError</span>: 503 Server Error: Service Unavailable for url: https://community.cloud.databricks.com/api/2.0/pipelines?max_results=100\n Response from server: \n { 'error_code': 'TEMPORARILY_UNAVAILABLE',\n  'message': 'The service at /api/2.0/pipelines is temporarily unavailable. '\n             'Please try again later.'}","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-4094000743659299>\u001B[0m in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# This function is provided for students who do not\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# want to work through the exercise of creating the pipeline.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mDA\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m<command-4094000743658882>\u001B[0m in \u001B[0;36mcreate_pipeline\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;31m# We need to delete the existing pipline so that we can apply updates\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0;31m# because some attributes are not mutable after creation.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpipelines\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdelete_by_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpipeline_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     response = self.client.pipelines().create(\n\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-f337616f-e42d-48be-b0bd-7d44fa0293ed/lib/python3.9/site-packages/dbacademy/dbrest/pipelines.py\u001B[0m in \u001B[0;36mdelete_by_name\u001B[0;34m(self, pipeline_name)\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdelete_by_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpipeline_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m         \u001B[0;32mimport\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m         \u001B[0mpipeline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_by_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpipeline_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mpipeline\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdelete_by_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"pipeline_id\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-f337616f-e42d-48be-b0bd-7d44fa0293ed/lib/python3.9/site-packages/dbacademy/dbrest/pipelines.py\u001B[0m in \u001B[0;36mget_by_name\u001B[0;34m(self, pipeline_name)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_by_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpipeline_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 36\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mpipeline\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     37\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"name\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mpipeline_name\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m                 \u001B[0mpipeline_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"pipeline_id\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-f337616f-e42d-48be-b0bd-7d44fa0293ed/lib/python3.9/site-packages/dbacademy/dbrest/pipelines.py\u001B[0m in \u001B[0;36mlist\u001B[0;34m(self, max_results)\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_results\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0mpipelines\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapi\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"GET\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf\"{self.base_uri}?max_results={max_results}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-f337616f-e42d-48be-b0bd-7d44fa0293ed/lib/python3.9/site-packages/dbacademy/rest/common.py\u001B[0m in \u001B[0;36mapi\u001B[0;34m(self, _http_method, _endpoint_path, _data, _expected, _result_type, _base_url, **data)\u001B[0m\n\u001B[1;32m    189\u001B[0m             \u001B[0;31m# if self.verbose: print(json.dumps(data, indent=4))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_http_method\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdumps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 191\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_raise_for_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_expected\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    192\u001B[0m         \u001B[0;31m# TODO: Should we really return None on errors?  Kept for now for backwards compatibility.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    193\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m200\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatus_code\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m300\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-f337616f-e42d-48be-b0bd-7d44fa0293ed/lib/python3.9/site-packages/dbacademy/rest/common.py\u001B[0m in \u001B[0;36m_raise_for_status\u001B[0;34m(response, expected)\u001B[0m\n\u001B[1;32m    282\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;36m400\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatus_code\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m500\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    283\u001B[0m             \u001B[0me\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDatabricksApiException\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhttp_exception\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 284\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    285\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    286\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mdeprecated\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreason\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"Use ApiClient.api\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maction\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"error\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mHTTPError\u001B[0m: 503 Server Error: Service Unavailable for url: https://community.cloud.databricks.com/api/2.0/pipelines?max_results=100\n Response from server: \n { 'error_code': 'TEMPORARILY_UNAVAILABLE',\n  'message': 'The service at /api/2.0/pipelines is temporarily unavailable. '\n             'Please try again later.'}"]}}],"execution_count":0},{"cell_type":"code","source":["DA.validate_pipeline_config()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c2ef92c5-b89e-4169-a7c4-34a0547a4a45","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"f98768ac-cbcc-42a2-8c51-ffdc3778aa11\"/>\n\n\n## Schedule a Notebook Job\n\nWhen using the Jobs UI to orchestrate a workload with multiple tasks, you'll always begin by scheduling a single task.\n\nBefore we start run the following cell to get the values used in this step."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8cbfbded-2470-40da-b718-f17f7915591f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["DA.print_job_config()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e65743f8-cf14-4f02-950e-43698941663f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"fab2a427-5d5a-4a82-8947-c809d815c2a3\"/>\n\n\nHere, we'll start by scheduling the next notebook.\n\nSteps:\n1. Click the **Workflows** button on the sidebar\n1. Select the **Jobs** tab.\n1. Click the blue **Create Job** button\n1. Configure the task:\n    1. Enter **Batch-Job** for the task name\n    1. For **Type**, select **Notebook**\n    1. For **Path**, select the **Batch Notebook Path** value provided in the cell above\n    1. From the **Cluster** dropdown, under **Existing All Purpose Clusters**, select your cluster\n    1. Click **Create**\n1. In the top-left of the screen, rename the job (not the task) from **`Batch-Job`** (the defaulted value) to the **Job Name** value provided in the cell above.\n1. Click the blue **Run now** button in the top right to start the job.\n\n<img src=\"https://files.training.databricks.com/images/icon_note_24.png\"> **Note**: When selecting your all purpose cluster, you will get a warning about how this will be billed as all purpose compute. Production jobs should always be scheduled against new job clusters appropriately sized for the workload, as this is billed at a much lower rate."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"09cbc6d0-096e-4b20-aa97-35b8575ec591","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"1ab345ce-dff4-4a99-ad45-209793ddc581\"/>\n\n\n## Schedule a DLT Pipeline as a Task\n\nIn this step, we'll add a DLT pipeline to execute after the success of the task we configured at the start of this lesson.\n\nSteps:\n1. At the top left of your screen, you'll see the **Runs** tab is currently selected; click the **Tasks** tab.\n1. Click the large blue circle with a **+** at the center bottom of the screen to add a new task\n1. Configure the task:\n    1. Enter **DLT** for the task name\n    1. For **Type**, select  **Delta Live Tables pipeline**\n    1. For **Pipeline**, select the DLT pipeline you configured previously in this exercise<br/>\n    Note: The pipeline will start with **DLT-Job-Lab-92** and will end with your email address.\n    1. The **Depends on** field defaults to your previously defined task, **Batch-Job** - leave this value as-is.\n    1. Click the blue **Create task** button\n\nYou should now see a screen with 2 boxes and a downward arrow between them. \n\nYour **`Batch-Job`** task will be at the top, leading into your **`DLT`** task."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7720a714-2a40-4b2b-bc10-35182cfce201","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"dd4e16c5-1842-4642-8159-117cfc84d4b4\"/>\n\n\n## Schedule an Additional Notebook Task\n\nAn additional notebook has been provided which queries some of the DLT metrics and the gold table defined in the DLT pipeline. \n\nWe'll add this as a final task in our job.\n\nSteps:\n1. Click the large blue circle with a **+** at the center bottom of the screen to add a new task\nSteps:\n1. Configure the task:\n    1. Enter **Query-Results** for the task name\n    1. For **Type**, select **Notebook**\n    1. For **Path**, select the **Query Notebook Path** value provided in the cell above\n    1. From the **Cluster** dropdown, under **Existing All Purpose Clusters**, select your cluster\n    1. The **Depends on** field defaults to your previously defined task, **DLT** - leave this value as-is.\n    1. Click the blue **Create task** button\n    \nClick the blue **Run now** button in the top right of the screen to run this job.\n\nFrom the **Runs** tab, you will be able to click on the start time for this run under the **Active runs** section and visually track task progress.\n\nOnce all your tasks have succeeded, review the contents of each task to confirm expected behavior."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2a6e44a3-48a5-4b27-ac23-efb3bd2dffa3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# ANSWER\n\n# This function is provided for students who do not \n# want to work through the exercise of creating the job.\nDA.create_job()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0f6013cc-7227-4fd6-b613-5343bbc57779","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["DA.validate_job_config()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dc7c1cfe-3244-43fe-ac29-ed3642546085","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["# ANSWER\n\n# This function is provided to start the job and  \n# block until it has completed, canceled or failed\nDA.start_job()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b0725d63-7bc9-40a0-9ef6-85c0d8b62f7f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c4c5a31a-39d5-406d-9ebe-14838b9bd52a","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DE 9.2.1L - Lab Instructions","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4094000743659290}},"nbformat":4,"nbformat_minor":0}
