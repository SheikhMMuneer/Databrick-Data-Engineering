{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"44615320-10ed-4b9d-b54c-c46a6f308947","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"bfb2d018-5d5a-4475-bf1e-293e2a5b0100\"/>\n\n# Data Engineering with Databricks\n\nThis course prepares you for topics in the Databricks Certified Associate Data Engineer certification exam.\n\nData professionals from all walks of life will benefit from this comprehensive introduction to the components of the Databricks Lakehouse Platform that directly support putting ETL pipelines into production. You will leverage SQL and Python to define and schedule pipelines that incrementally process new data from a variety of data sources to power analytic applications and dashboards in the Lakehouse. This course offers hands-on instruction in Databricks Data Science & Engineering Workspace, Databricks SQL, Delta Live Tables, Databricks Repos, Databricks Task Orchestration, and the Unity Catalog.\n\n**Duration:** 2 full days or 4 half days\n\n#### Objectives\n- Leverage the Databricks Lakehouse Platform to perform core responsibilities for data pipeline development\n- Use SQL and Python to write production data pipelines to extract, transform, and load data into tables and views in the Lakehouse\n- Simplify data ingestion and incremental change propagation using Databricks-native features and syntax, including Delta Live Tables\n- Orchestrate production pipelines to deliver fresh results for ad-hoc analytics and dashboarding\n\n#### Prerequisites\n- Basic knowledge of SQL query syntax, including writing queries using `SELECT`, `WHERE`, `GROUP BY`, `ORDER BY`, `LIMIT`, and `JOIN`\n- Basic knowledge of SQL DDL statements to create, alter, and drop databases and tables\n- Basic knowledge of SQL DML statements, including `DELETE`, `INSERT`, `UPDATE`, and `MERGE`\n- Experience with or knowledge of data engineering practices on cloud platforms, including cloud features such as virtual machines, object storage, identity management, and metastores"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"75c9b5e3-8d3f-4642-8ce4-f5cb2d1bf8cc","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"2fbffe4f-04e7-46db-8ed0-af4991565700\"/>\n\n## Course Agenda\n\nDay 1\n\n| Folder | Module Name |\n| --- | --- |\n| `01 - Databricks Workspace and Services` | Introduction to Databricks Workspace and Services |\n| `02 - Delta Lake` | Introduction to Delta Lake |\n| `03 - Relational Entities on Databricks` | Relational Entities on Databricks |\n| `04 - ETL with Spark SQL` | ETL with Spark SQL |\n| `05 - OPTIONAL Python for Spark SQL` | Just Enough Python for Spark SQL |\n| `06 - Incremental Data Processing` | Incremental Data Processing with Structured Streaming and Auto Loader |\n\nDay 2\n\n| Folder | Module Name |\n| --- | --- |\n| `07 - Multi-Hop Architecture` | Medallion Architecture in the Data Lakehouse |\n| `08 - Delta Live Tables` | Using Delta Live Tables |\n| `09 - Task Orchestration with Jobs` | Task Orchestration with Databricks Jobs |\n| `10 - Running a DBSQL Query` | Running Your First Databricks SQL Query |\n| `11 - Managing Permissions` | Managing Permissions in the Lakehouse |\n| `12 - Productionalizing Dashboards and Queries in DBSQL` | Productionalizing Dashboards and Queries in Databricks SQL |\n\nThe notebooks included in each module are listed below."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"053bd5b1-b633-4134-9af3-6d8b01daf1b8","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"8bcc5220-9489-49ec-ba62-8260e9871f38\"/>\n\n\n\n## 01 - Databricks Workspace and Services\n* [DE 1.1 - Create and Manage Interactive Clusters]($./01 - Databricks Workspace and Services/DE 1.1 - Create and Manage Interactive Clusters)\n* [DE 1.2 - Notebook Basics]($./01 - Databricks Workspace and Services/DE 1.2 - Notebook Basics)\n* [DE 1.3L - Getting Started with the Databricks Platform Lab]($./01 - Databricks Workspace and Services/DE 1.3L - Getting Started with the Databricks Platform Lab)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c73459b6-e5ab-4ddb-95fa-77c0cb48963f","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"c57df770-302b-4b87-ad3b-c34bdef01029\"/>\n\n\n\n## 02 - Delta Lake\n* [DE 2.1 - Managing Delta Tables]($./02 - Delta Lake/DE 2.1 - Managing Delta Tables)\n* [DE 2.2L - Manipulating Tables with Delta Lake Lab]($./02 - Delta Lake/DE 2.2L - Manipulating Tables with Delta Lake Lab)\n* [DE 2.3 - Advanced Delta Lake Features]($./02 - Delta Lake/DE 2.3 - Advanced Delta Lake Features)\n* [DE 2.4L - Delta Lake Versioning, Optimization, and Vacuuming Lab]($./02 - Delta Lake/DE 2.4L - Delta Lake Versioning, Optimization, and Vacuuming Lab)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"04063cc9-82ba-43c9-a589-b368f5f33a3f","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"6ed0e37b-3299-47fe-b78d-7f7e5fca9396\"/>\n\n\n## 03 - Relational Entities on Databricks\n* [DE 3.1 - Databases and Tables on Databricks]($./03 - Relational Entities on Databricks/DE 3.1 - Databases and Tables on Databricks)\n* [DE 3.2A - Views and CTEs on Databricks]($./03 - Relational Entities on Databricks/DE 3.2A - Views and CTEs on Databricks)\n* [DE 3.3L - Databases, Tables & Views Lab]($./03 - Relational Entities on Databricks/DE 3.3L - Databases, Tables & Views Lab)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"028c799a-57fe-43c8-aed8-3c7eeec7f8b7","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"f958dddc-d0e2-4c21-82ad-db6aaebabda4\"/>\n\n\n## 04 - ETL with Spark SQL\n* [DE 4.1 - Querying Files Directly]($./04 - ETL with Spark SQL/DE 4.1 - Querying Files Directly)\n* [DE 4.2 - Providing Options for External Sources]($./04 - ETL with Spark SQL/DE 4.2 - Providing Options for External Sources)\n* [DE 4.3 - Creating Delta Tables]($./04 - ETL with Spark SQL/DE 4.3 - Creating Delta Tables)\n* [DE 4.4 - Writing to Tables]($./04 - ETL with Spark SQL/DE 4.4 - Writing to Tables)\n* [DE 4.5L - Extract and Load Data Lab]($./04 - ETL with Spark SQL/DE 4.5L - Extract and Load Data Lab)\n* [DE 4.6 - Cleaning Data]($./04 - ETL with Spark SQL/DE 4.6 - Cleaning Data)\n* [DE 4.7 - Advanced SQL Transformations]($./04 - ETL with Spark SQL/DE 4.7 - Advanced SQL Transformations)\n* [DE 4.8 - SQL UDFs and Control Flow]($./04 - ETL with Spark SQL/DE 4.8 - SQL UDFs and Control Flow)\n* [DE 4.9L - Reshaping Data Lab]($./04 - ETL with Spark SQL/DE 4.9L - Reshaping Data Lab)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"335d6c37-0bda-43a0-bda6-0738bdc6d0f2","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"ce1da17d-44fa-47f4-bd66-af6e0c0f179d\"/>\n\n\n\n## 05 - OPTIONAL Python for Spark SQL\n* [DE 5.1 - Python Basics]($./05 - OPTIONAL Python for Spark SQL/DE 5.1 - Python Basics)\n* [DE 5.2 - Python Control Flow]($./05 - OPTIONAL Python for Spark SQL/DE 5.2 - Python Control Flow)\n* [DE 5.3L - Python for SQL Lab]($./05 - OPTIONAL Python for Spark SQL/DE 5.3L - Python for SQL Lab)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"754b694c-37dd-423d-bde6-72239b3865e1","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"8fbeed27-4056-4024-afc7-859873916b70\"/>\n\n\n\n## 06 - Incremental Data Processing\n* [DE 6.1 - Incremental Data Ingestion with Auto Loader.py]($./06 - Incremental Data Processing/DE 6.1 - Incremental Data Ingestion with Auto Loader)\n* [DE 6.2 - Reasoning about Incremental Data.py]($./06 - Incremental Data Processing/DE 6.2 - Reasoning about Incremental Data)\n* [DE 6.3L - Using Auto Loader and Structured Streaming with Spark SQL Lab.py]($./06 - Incremental Data Processing/DE 6.3L - Using Auto Loader and Structured Streaming with Spark SQL Lab)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"99bf9350-688f-4bd5-a768-7835542ef163","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"2d9f1a05-fd79-4766-a492-74c21c1d6bad\"/>\n\n\n\n## 07 - Multi-Hop Architecture\n* [DE 7.1 - Incremental Multi-Hop in the Lakehouse]($./07 - Multi-Hop Architecture/DE 7.1 - Incremental Multi-Hop in the Lakehouse)\n* [DE 7.2L - Propagating Incremental Updates with Structured Streaming and Delta Lake Lab]($./07 - Multi-Hop Architecture/DE 7.2L - Propagating Incremental Updates with Structured Streaming and Delta Lake Lab)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"12012048-5fa9-4d00-8f20-3983a7eed6ff","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"c633fc58-9310-48e0-bcfa-974b30b75849\"/>\n\n\n\n## 08 - Delta Live Tables\n* DE 8.1 - DLT\n  * [DE 8.1.1 - DLT UI Walkthrough]($./08 - Delta Live Tables/DE 8.1 - DLT/DE 8.1.1 - DLT UI Walkthrough)\n  * [DE 8.1.2 - SQL for Delta Live Tables]($./08 - Delta Live Tables/DE 8.1 - DLT/DE 8.1.2 - SQL for Delta Live Tables)\n  * [DE 8.1.3 - Pipeline Results]($./08 - Delta Live Tables/DE 8.1 - DLT/DE 8.1.3 - Pipeline Results)\n\n* DE 8.2 - DLT Lab\n  * [DE 8.2.1L - Lab Instructions]($./08 - Delta Live Tables/DE 8.2 - DLT Lab/DE 8.2.1L - Lab Instructions)\n  * [DE 8.2.2L - Migrating a SQL Pipeline to DLT Lab]($./08 - Delta Live Tables/DE 8.2 - DLT Lab/DE 8.2.2L - Migrating a SQL Pipeline to DLT Lab)\n  * [DE 8.2.3L - Lab Conclusion]($./08 - Delta Live Tables/DE 8.2 - DLT Lab/DE 8.2.3L - Lab Conclusion)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"419d8298-bdf1-4902-80fd-b93aaf41be1d","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"74e6ecb4-6268-4c2c-a6a1-726b02cf392e\"/>\n\n\n## 09 - Task Orchestration with Jobs\n* DE 9.1 - Scheduling Tasks with the Jobs UI\n  * [DE 9.1.1 - Task Orchestration with Databricks Jobs]($./09 - Task Orchestration with Jobs/DE 9.1 - Scheduling Tasks with the Jobs UI/DE 9.1.1 - Task Orchestration with Databricks Jobs)\n  * [DE 9.1.2 - Reset]($./09 - Task Orchestration with Jobs/DE 9.1 - Scheduling Tasks with the Jobs UI/DE 9.1.2 - Reset)\n  * [DE 9.1.3 - DLT Job]($./09 - Task Orchestration with Jobs/DE 9.1 - Scheduling Tasks with the Jobs UI/DE 9.1.3 - DLT Job)\n\n* DE 9.2L - Jobs Lab\n  * [DE 9.2.1L - Lab Instructions]($./09 - Task Orchestration with Jobs/DE 9.2L - Jobs Lab/DE 9.2.1L - Lab Instructions)\n  * [DE 9.2.2L - Batch Job]($./09 - Task Orchestration with Jobs/DE 9.2L - Jobs Lab/DE 9.2.2L - Batch Job)\n  * [DE 9.2.3L - DLT Job]($./09 - Task Orchestration with Jobs/DE 9.2L - Jobs Lab/DE 9.2.3L - DLT Job)\n  * [DE 9.2.4L - Query Results Job]($./09 - Task Orchestration with Jobs/DE 9.2L - Jobs Lab/DE 9.2.4L - Query Results Job)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a2f975a3-e7a1-47aa-95e6-a3460882ae6e","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"498a81f3-4eda-49ac-aadb-ac33360af496\"/>\n\n## 10 - Running a DBSQL Query\n* [DE 10.1 - Navigating Databricks SQL and Attaching to Endpoints]($./10 - Running a DBSQL Query/DE 10.1 - Navigating Databricks SQL and Attaching to Endpoints)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"098c63a1-e1fd-4595-b5bf-ac23f8db24f2","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"ea5067ca-80b5-44d0-9446-8c591649d515\"/>\n\n\n## 11 - Managing Permissions\n* [DE 11.1 - Managing Permissions for Databases, Tables, and Views]($./11 - Managing Permissions/DE 11.1 - Managing Permissions for Databases, Tables, and Views)\n* [DE 11.2L - Configuring Privileges for Production Data and Derived Tables Lab]($./11 - Managing Permissions/DE 11.2L - Configuring Privileges for Production Data and Derived Tables Lab)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"503064ab-977e-45ed-9bb6-a777e9e9759b","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"76d731fd-01f1-4602-9d7b-4554eed88b8f\"/>\n\n\n## 12 - Productionalizing Dashboards and Queries in DBSQL\n* [DE 12.1 - Last Mile ETL with DBSQL]($./12 - Productionalizing Dashboards and Queries in DBSQL/DE 12.1 - Last Mile ETL with DBSQL)\n* DE 12.2L - OPTIONAL Capstone\n  * [DE 12.2.1L - Instructions and Configuration]($./12 - Productionalizing Dashboards and Queries in DBSQL/DE 12.2L - OPTIONAL Capstone/DE 12.2.1L - Instructions and Configuration)\n  * [DE 12.2.2L - DLT Task]($./12 - Productionalizing Dashboards and Queries in DBSQL/DE 12.2L - OPTIONAL Capstone/DE 12.2.2L - DLT Task)\n  * [DE 12.2.3L - Land New Data]($./12 - Productionalizing Dashboards and Queries in DBSQL/DE 12.2L - OPTIONAL Capstone/DE 12.2.3L - Land New Data)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"24f38e36-f640-45e0-bd23-2ad19cbe8b8f","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"44fe2fa5-7029-4056-a12e-326bacf9fd6e","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"00 - Course Agenda","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4094000743660098}},"nbformat":4,"nbformat_minor":0}
