{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d41c12f1-1cb7-4703-ba72-4215aeb48e34","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"931bf77d-810b-4930-b45c-b00c184029a0\"/>\n\n\n# SQL UDFs and Control Flow\n\nDatabricks added support for User Defined Functions (UDFs) registered natively in SQL starting in DBR 9.1.\n\nThis feature allows users to register custom combinations of SQL logic as functions in a database, making these methods reusable anywhere SQL can be run on Databricks. These functions leverage Spark SQL directly, maintaining all of the optimizations of Spark when applying your custom logic to large datasets.\n\nIn this notebook, we'll first have a simple introduction to these methods, and then explore how this logic can be combined with **`CASE`** / **`WHEN`** clauses to provide reusable custom control flow logic.\n\n## Learning Objectives\nBy the end of this lesson, you should be able to:\n* Define and registering SQL UDFs\n* Describe the security model used for sharing SQL UDFs\n* Use **`CASE`** / **`WHEN`** statements in SQL code\n* Leverage **`CASE`** / **`WHEN`** statements in SQL UDFs for custom control flow"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"92495e6c-92a9-493a-94bf-92b84e038572","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"df80ac46-fb12-44ed-bb37-dcc5a4d73d4a\"/>\n\n\n## Setup\nRun the following cell to setup your environment."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fd653062-066f-49a7-afce-586dd6e6c408","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup-04.8"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3b432175-2b98-4d7a-829a-8abaf948e03a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Python interpreter will be restarted.\nPython interpreter will be restarted.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Python interpreter will be restarted.\nPython interpreter will be restarted.\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02\"\n\nValidating the locally installed datasets:\n| listing local files...(7 seconds)\n| completed (7 seconds total)\n\nCreating & using the schema \"munirsheikhcloudseekho_0lj9_da_dewd\"...(0 seconds)\nPredefined tables in \"munirsheikhcloudseekho_0lj9_da_dewd\":\n| -none-\n\nPredefined paths variables:\n| DA.paths.working_dir: dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks\n| DA.paths.user_db:     dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/database.db\n| DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02\n| DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/_checkpoints\n\nSetup completed (9 seconds)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02\"\n\nValidating the locally installed datasets:\n| listing local files...(7 seconds)\n| completed (7 seconds total)\n\nCreating & using the schema \"munirsheikhcloudseekho_0lj9_da_dewd\"...(0 seconds)\nPredefined tables in \"munirsheikhcloudseekho_0lj9_da_dewd\":\n| -none-\n\nPredefined paths variables:\n| DA.paths.working_dir: dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks\n| DA.paths.user_db:     dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/database.db\n| DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02\n| DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks/_checkpoints\n\nSetup completed (9 seconds)\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"f4fec594-3cd7-43c9-b88e-3ccd3a99c6be\"/>\n\n\n## Create a Simple Dataset\n\nFor this notebook, we'll consider the following dataset, registered here as a temporary view."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fdc98104-3184-4046-903d-a904d442e633","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql\nCREATE OR REPLACE TEMPORARY VIEW foods(food) AS VALUES\n(\"beef\"),\n(\"beans\"),\n(\"potatoes\"),\n(\"bread\");\n\nSELECT * FROM foods"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"538cf691-e81e-48a1-bfe0-3357267e07ce","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["beef"],["beans"],["potatoes"],["bread"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"food","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>food</th></tr></thead><tbody><tr><td>beef</td></tr><tr><td>beans</td></tr><tr><td>potatoes</td></tr><tr><td>bread</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"65577a77-c917-441c-895b-8ba146c837ff\"/>\n\n\n## SQL UDFs\nAt minimum, a SQL UDF requires a function name, optional parameters, the type to be returned, and some custom logic.\n\nBelow, a simple function named **`yelling`** takes one parameter named **`text`**. It returns a string that will be in all uppercase letters with three exclamation points added to the end."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a6420bc5-c81e-4abf-bdc3-19a387f8317c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql\nCREATE OR REPLACE FUNCTION yelling(text STRING)\nRETURNS STRING\nRETURN concat(upper(text), \"!!!\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"69a050fc-f3e5-4b1f-ad1d-a4d121f0fcd5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"4cffc92d-3133-45ba-97c8-b0bc4c9e419b\"/>\n\n\nNote that this function is applied to all values of the column in a parallel fashion within the Spark processing engine. SQL UDFs are an efficient way to define custom logic that is optimized for execution on Databricks."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0cf3c8b7-c477-45e7-8878-91bbe2aea547","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql\nSELECT yelling(food) FROM foods"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fc4bbb29-b1a0-461c-bf38-2a5dee787859","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["BEEF!!!"],["BEANS!!!"],["POTATOES!!!"],["BREAD!!!"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"spark_catalog.munirsheikhcloudseekho_0lj9_da_dewd.yelling(food)","type":"\"string\"","metadata":"{\"__autoGeneratedAlias\":\"true\"}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>spark_catalog.munirsheikhcloudseekho_0lj9_da_dewd.yelling(food)</th></tr></thead><tbody><tr><td>BEEF!!!</td></tr><tr><td>BEANS!!!</td></tr><tr><td>POTATOES!!!</td></tr><tr><td>BREAD!!!</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"e1749d08-2186-4e1c-9214-18c8199388af\"/>\n\n\n## Scoping and Permissions of SQL UDFs\n\nNote that SQL UDFs will persist between execution environments (which can include notebooks, DBSQL queries, and jobs).\n\nWe can describe the function to see where it was registered and basic information about expected inputs and what is returned."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9fa3542b-1c39-4e95-b71d-501a2beea1a0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql\nDESCRIBE FUNCTION yelling"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1621111b-1971-4444-a450-9df757f8a1f0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Function: spark_catalog.munirsheikhcloudseekho_0lj9_da_dewd.yelling"],["Type:     SCALAR"],["Input:    text STRING"],["Returns:  STRING"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"function_desc","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>function_desc</th></tr></thead><tbody><tr><td>Function: spark_catalog.munirsheikhcloudseekho_0lj9_da_dewd.yelling</td></tr><tr><td>Type:     SCALAR</td></tr><tr><td>Input:    text STRING</td></tr><tr><td>Returns:  STRING</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"6a6eb6c6-ffc8-49d9-a39a-a5e1f6c230af\"/>\n\n\nBy describing extended, we can get even more information. \n\nNote that the **`Body`** field at the bottom of the function description shows the SQL logic used in the function itself."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b842817c-38ba-44c9-a721-d996c78ac291","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql\nDESCRIBE FUNCTION EXTENDED yelling"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"05264a2d-eb27-451f-aa45-23501bdb07f7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Function:      spark_catalog.munirsheikhcloudseekho_0lj9_da_dewd.yelling"],["Type:          SCALAR"],["Input:         text STRING"],["Returns:       STRING"],["Deterministic: true"],["Data Access:   CONTAINS SQL"],["Configs:       spark.sql.hive.convertCTAS=true"],["               spark.sql.legacy.createHiveTableByDefault=false"],["               spark.sql.parquet.compression.codec=snappy"],["               spark.sql.sources.commitProtocolClass=com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol"],["               spark.sql.sources.default=delta"],["               spark.sql.streaming.stopTimeout=15s"],["Owner:         root"],["Create Time:   Sun Nov 13 18:42:03 UTC 2022"],["Body:          concat(upper(text), \"!!!\")"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"function_desc","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>function_desc</th></tr></thead><tbody><tr><td>Function:      spark_catalog.munirsheikhcloudseekho_0lj9_da_dewd.yelling</td></tr><tr><td>Type:          SCALAR</td></tr><tr><td>Input:         text STRING</td></tr><tr><td>Returns:       STRING</td></tr><tr><td>Deterministic: true</td></tr><tr><td>Data Access:   CONTAINS SQL</td></tr><tr><td>Configs:       spark.sql.hive.convertCTAS=true</td></tr><tr><td>               spark.sql.legacy.createHiveTableByDefault=false</td></tr><tr><td>               spark.sql.parquet.compression.codec=snappy</td></tr><tr><td>               spark.sql.sources.commitProtocolClass=com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol</td></tr><tr><td>               spark.sql.sources.default=delta</td></tr><tr><td>               spark.sql.streaming.stopTimeout=15s</td></tr><tr><td>Owner:         root</td></tr><tr><td>Create Time:   Sun Nov 13 18:42:03 UTC 2022</td></tr><tr><td>Body:          concat(upper(text), \"!!!\")</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"a31a4ad1-5608-4bfb-aae4-a411fe460385\"/>\n\n\nSQL UDFs exist as objects in the metastore and are governed by the same Table ACLs as databases, tables, or views.\n\nIn order to use a SQL UDF, a user must have **`USAGE`** and **`SELECT`** permissions on the function."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ea020cc3-20a9-45ee-8bd3-82ef81eee9ec","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"155c70b7-ed5e-47d2-9832-963aa18f3869\"/>\n\n\n## CASE/WHEN\n\nThe standard SQL syntactic construct **`CASE`** / **`WHEN`** allows the evaluation of multiple conditional statements with alternative outcomes based on table contents.\n\nAgain, everything is evaluated natively in Spark, and so is optimized for parallel execution."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a1815b4a-45bb-4dea-904b-f376f9bfb5ec","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql\nSELECT *,\n  CASE \n    WHEN food = \"beans\" THEN \"I love beans\"\n    WHEN food = \"potatoes\" THEN \"My favorite vegetable is potatoes\"\n    WHEN food <> \"beef\" THEN concat(\"Do you have any good recipes for \", food ,\"?\")\n    ELSE concat(\"I don't eat \", food)\n  END\nFROM foods"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ba0d13d7-dcdd-40bb-8f50-4eb77e60131d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["beef","I don't eat beef"],["beans","I love beans"],["potatoes","My favorite vegetable is potatoes"],["bread","Do you have any good recipes for bread?"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"food","type":"\"string\"","metadata":"{}"},{"name":"CASE WHEN (food = beans) THEN I love beans WHEN (food = potatoes) THEN My favorite vegetable is potatoes WHEN (NOT (food = beef)) THEN concat(Do you have any good recipes for , food, ?) ELSE concat(I don't eat , food) END","type":"\"string\"","metadata":"{\"__autoGeneratedAlias\":\"true\"}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>food</th><th>CASE WHEN (food = beans) THEN I love beans WHEN (food = potatoes) THEN My favorite vegetable is potatoes WHEN (NOT (food = beef)) THEN concat(Do you have any good recipes for , food, ?) ELSE concat(I don't eat , food) END</th></tr></thead><tbody><tr><td>beef</td><td>I don't eat beef</td></tr><tr><td>beans</td><td>I love beans</td></tr><tr><td>potatoes</td><td>My favorite vegetable is potatoes</td></tr><tr><td>bread</td><td>Do you have any good recipes for bread?</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"50bc0847-94d2-4167-befe-66e42b287ad0\"/>\n\n\n## Simple Control Flow Functions\n\nCombining SQL UDFs with control flow in the form of **`CASE`** / **`WHEN`** clauses provides optimized execution for control flows within SQL workloads.\n\nHere, we demonstrate wrapping the previous logic in a function that will be reusable anywhere we can execute SQL."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8621da89-0d5f-40d0-9856-6ecd256c37ff","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql\nCREATE FUNCTION foods_i_like(food STRING)\nRETURNS STRING\nRETURN CASE \n  WHEN food = \"beans\" THEN \"I love beans\"\n  WHEN food = \"potatoes\" THEN \"My favorite vegetable is potatoes\"\n  WHEN food <> \"beef\" THEN concat(\"Do you have any good recipes for \", food ,\"?\")\n  ELSE concat(\"I don't eat \", food)\nEND;"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"98cdce8a-67b4-4f53-9011-7c8b7555e3ed","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"05cb00cc-097c-4607-8738-ab4353536dda\"/>\n\n\nUsing this method on our data provides the desired outcome."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bb127f10-aee3-4174-8549-741868417961","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql\nSELECT foods_i_like(food) FROM foods"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7258dbbe-bd01-4130-89bf-8dd42fab9501","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["I don't eat beef"],["I love beans"],["My favorite vegetable is potatoes"],["Do you have any good recipes for bread?"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"spark_catalog.munirsheikhcloudseekho_0lj9_da_dewd.foods_i_like(food)","type":"\"string\"","metadata":"{\"__autoGeneratedAlias\":\"true\"}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>spark_catalog.munirsheikhcloudseekho_0lj9_da_dewd.foods_i_like(food)</th></tr></thead><tbody><tr><td>I don't eat beef</td></tr><tr><td>I love beans</td></tr><tr><td>My favorite vegetable is potatoes</td></tr><tr><td>Do you have any good recipes for bread?</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<i18n value=\"24ee3267-9ddb-4cf5-9081-273502f5252a\"/>\n\n\nWhile the example provided here are simple string methods, these same basic principles can be used to add custom computations and logic for native execution in Spark SQL. \n\nEspecially for enterprises that might be migrating users from systems with many defined procedures or custom-defined formulas, SQL UDFs can allow a handful of users to define the complex logic needed for common reporting and analytic queries."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2ae5d4b4-2915-4414-875b-5ec8d5b4067b","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["<i18n value=\"9405ddea-5fb0-4168-9fd2-2b462d5809d9\"/>\n\n \nRun the following cell to delete the tables and files associated with this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b45dc2c9-14c7-4322-9599-7d6e949d9be9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%python\nDA.cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dd5156c4-3d62-4aa7-865e-a7f64c0f44a6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Resetting the learning environment:\n| dropping the schema \"munirsheikhcloudseekho_0lj9_da_dewd\"...(0 seconds)\n| removing the working directory \"dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks\"...(0 seconds)\n\nValidating the locally installed datasets:\n| listing local files...(8 seconds)\n| completed (8 seconds total)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Resetting the learning environment:\n| dropping the schema \"munirsheikhcloudseekho_0lj9_da_dewd\"...(0 seconds)\n| removing the working directory \"dbfs:/mnt/dbacademy-users/munirsheikhcloudseekho@gmail.com/data-engineering-with-databricks\"...(0 seconds)\n\nValidating the locally installed datasets:\n| listing local files...(8 seconds)\n| completed (8 seconds total)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"faf81d91-8ecb-4df5-8f67-d1a13d20616a","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"DE 4.8 - SQL UDFs and Control Flow","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4094000743658983}},"nbformat":4,"nbformat_minor":0}
